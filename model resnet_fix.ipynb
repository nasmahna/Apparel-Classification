{"cells":[{"cell_type":"markdown","metadata":{"id":"WE5CvdF_Dzu3"},"source":["# Apparel images dataset Classification \n","### Transfer Learning using keras application"]},{"cell_type":"markdown","metadata":{"id":"qu30SI8NDzu8"},"source":["Transfer learning is a machine learning method where a model developed for a task is reused as the starting point for a model on a second task\n","\n","<img src=\"https://learnopencv.com/wp-content/uploads/2019/05/transfer-learning-1024x574.jpg\" alt=\"drawing\" width=\"500\"/>\n","\n","In this notebook the model use resnet 50 model and add some final layer which are going to be trained."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"slKCjYqbDzu_","outputId":"0beb4dc8-0bf4-4bfc-a413-d1a8c0756489"},"outputs":[{"name":"stdout","output_type":"stream","text":["../DATASET/CNN_DATASET_PAKAIAN\n","../DATASET/CNN_DATASET_PAKAIAN\\black_dress\n","../DATASET/CNN_DATASET_PAKAIAN\\black_pants\n","../DATASET/CNN_DATASET_PAKAIAN\\black_shirt\n","../DATASET/CNN_DATASET_PAKAIAN\\black_shoes\n","../DATASET/CNN_DATASET_PAKAIAN\\black_shorts\n","../DATASET/CNN_DATASET_PAKAIAN\\blue_dress\n","../DATASET/CNN_DATASET_PAKAIAN\\blue_pants\n","../DATASET/CNN_DATASET_PAKAIAN\\blue_shirt\n","../DATASET/CNN_DATASET_PAKAIAN\\blue_shoes\n","../DATASET/CNN_DATASET_PAKAIAN\\blue_shorts\n","../DATASET/CNN_DATASET_PAKAIAN\\brown_pants\n","../DATASET/CNN_DATASET_PAKAIAN\\brown_shoes\n","../DATASET/CNN_DATASET_PAKAIAN\\brown_shorts\n","../DATASET/CNN_DATASET_PAKAIAN\\green_pants\n","../DATASET/CNN_DATASET_PAKAIAN\\green_shirt\n","../DATASET/CNN_DATASET_PAKAIAN\\green_shoes\n","../DATASET/CNN_DATASET_PAKAIAN\\green_shorts\n","../DATASET/CNN_DATASET_PAKAIAN\\red_dress\n","../DATASET/CNN_DATASET_PAKAIAN\\red_pants\n","../DATASET/CNN_DATASET_PAKAIAN\\red_shoes\n","../DATASET/CNN_DATASET_PAKAIAN\\white_dress\n","../DATASET/CNN_DATASET_PAKAIAN\\white_pants\n","../DATASET/CNN_DATASET_PAKAIAN\\white_shoes\n","../DATASET/CNN_DATASET_PAKAIAN\\white_shorts\n"]}],"source":["import numpy as np\n","import pandas as pd\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","# Models \n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.layers import Input\n","from tensorflow.keras.layers import Flatten, Dense, Dropout, Conv2D, MaxPooling2D\n","\n","import os\n","\n","folder_path = '../DATASET/CNN_DATASET_PAKAIAN'\n","for dirname, _, filenames in os.walk(folder_path):\n","    print(dirname)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B5WJKB5qDzvD"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fWAxKbuVDzvR"},"outputs":[],"source":["from keras.preprocessing import image\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","%matplotlib inline"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Le3F6NkyDzvS"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bUtZdDmVDzvT"},"outputs":[],"source":["train_datagen = ImageDataGenerator(\n","                fill_mode = 'nearest',\n","                validation_split=0.2\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p2XgquIGDzvU","outputId":"c8164b0c-9bfd-4c68-9e35-93aee59596ef"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 9115 images belonging to 24 classes.\n","Found 2270 images belonging to 24 classes.\n"]}],"source":["train_generator=train_datagen.flow_from_directory(\n","    folder_path,\n","    target_size=(255,255),\n","    color_mode='rgb',\n","    class_mode='categorical',\n","    subset='training',\n",")\n","validation_generator=train_datagen.flow_from_directory(\n","    folder_path,\n","    target_size=(255,255),\n","    color_mode='rgb',\n","    class_mode='categorical',\n","    subset='validation',\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KcJymK9hDzvV"},"outputs":[],"source":["tf.keras.applications.imagenet_utils.preprocess_input(\n","    train_generator, data_format=None, mode='caffe'\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M0g1N280DzvY"},"outputs":[],"source":["from keras.applications import ResNet50\n","i = tf.keras.layers.Input([None, None, 3], dtype = tf.uint8)\n","x = tf.cast(i, tf.float32)\n","x = tf.keras.applications.mobilenet.preprocess_input(x)\n","core = tf.keras.applications.ResNet50(input_shape=(255,255,3), include_top=False)\n","x = core(x)\n","model = tf.keras.Model(inputs=[i], outputs=[x])\n","\n","image = tf.image.decode_png(tf.io.read_file('file.png'))\n","result = model(image)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uKNj7KrRDzvZ","outputId":"71b7135e-52e1-4987-dc37-324193549882"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_3\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," resnet50 (Functional)       (None, 8, 8, 2048)        23587712  \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 6, 6, 64)          1179712   \n","                                                                 \n"," max_pooling2d_3 (MaxPooling  (None, 3, 3, 64)         0         \n"," 2D)                                                             \n","                                                                 \n"," flatten_3 (Flatten)         (None, 576)               0         \n","                                                                 \n"," dense_6 (Dense)             (None, 64)                36928     \n","                                                                 \n"," dropout_3 (Dropout)         (None, 64)                0         \n","                                                                 \n"," dense_7 (Dense)             (None, 24)                1560      \n","                                                                 \n","=================================================================\n","Total params: 24,805,912\n","Trainable params: 1,218,200\n","Non-trainable params: 23,587,712\n","_________________________________________________________________\n"]}],"source":["from keras.applications import ResNet50\n","model = tf.keras.models.Sequential([\n","    ResNet50(input_shape=(255,255,3), include_top=False),\n","])\n","for layer in model.layers:\n","  layer.trainable = False\n","\n","model.add(Conv2D(64, (3,3), activation='relu'))\n","model.add(MaxPooling2D(2,2))\n","model.add(Flatten())\n","model.add(Dense(64, activation='relu'))\n","model.add(Dropout(0.4))\n","model.add(Dense(24, activation='softmax'))\n","\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X2tOOtTeDzvc"},"outputs":[],"source":["model.compile(loss='categorical_crossentropy',\n","             optimizer=keras.optimizers.Adam(learning_rate=0.01),\n","             metrics=['accuracy'], run_eagerly=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hKTvcL_FDzvd","outputId":"660ec339-a280-44b7-f1f8-e1bbcec3949a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/5\n"," 87/285 [========>.....................] - ETA: 47:50 - loss: 5.8804 - accuracy: 0.0837"]}],"source":["history = model.fit(train_generator,\n","                    validation_data=validation_generator,\n","                    epochs=5,\n","                    verbose=1,\n","                    )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ghjbfg1sDzvd"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","plt.plot(history.history['accuracy'])\n","plt.plot(history.history['val_accuracy'])\n","plt.title('Model accuracy')\n","plt.ylabel('Accuracy')\n","plt.xlabel('Epoch')\n","plt.legend(['Train', 'Validation'], loc='lower right')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7U9nltV5Dzvu"},"outputs":[],"source":["plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('Model Loss')\n","plt.ylabel('loss')\n","plt.xlabel('Epoch')\n","plt.legend(['Train', 'Validation'], loc='lower right')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KhDZ5AjoDzvv"},"outputs":[],"source":["model.save('/kaggle/working/model.h5')"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.2"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"27f6fea6f47ae512550f0b8facdbd035a93e1dd89633f7bf2dd00a2502c71d0d"}},"colab":{"provenance":[{"file_id":"1w3PVxBHdB82e-6JvPNiU0aLEhXRh1KvT","timestamp":1673360531573}]}},"nbformat":4,"nbformat_minor":0}